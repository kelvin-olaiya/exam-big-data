{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Big Data Exam Report @ UniBo a.y. 2023/2024\n",
    "\n",
    "- Manuel Andruccioli\n",
    "- Kelvin Olaiya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "val sc = new SparkContext(\"local[*]\", \"BigDataExam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures and definitions\n",
    "\n",
    "### Utility function for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCharIndexes(line: String, char: Char): Seq[Int] = line.zipWithIndex.filter(_._1 == char).map(_._2) \n",
    "def splitAt(s: String, indices: Seq[Int]): Seq[String] = indices match {\n",
    "  case h +: t => s.splitAt(h) match {\n",
    "    case (a, b) => a +: splitAt(b, t.map(_ - h))\n",
    "  }\n",
    "  case Nil => Seq(s)\n",
    "}\n",
    "def parseCSVLine(l: String): Seq[String] = {\n",
    "  val apices = getCharIndexes(l, '\"').grouped(2).map { case Seq(a, b) => (a, b) }.toSeq\n",
    "  val commas = getCharIndexes(l, ',').filter(i => !apices.exists { case (a, b) => a < i && i < b })\n",
    "  return splitAt(l, commas).map(_.dropWhile(s => s == ',' || s == ' ')).map(_.replaceAll(\"^\\\"|\\\"$\", \"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Track(\n",
    "  uri: String,\n",
    "  name: String,\n",
    "  duration: Int,\n",
    "  explicit: Boolean,\n",
    "  artists: String,            // List of artists uri, separated by |\n",
    "  available_markets: String,  // List of markets, separated by |\n",
    "  album_uri: String,\n",
    "  popularity: Int,\n",
    ")\n",
    "\n",
    "object Track {\n",
    "  def fromCSVLine(line: String): Option[Track] = \n",
    "    parseCSVLine(line) match {\n",
    "      case Seq(uri, name, duration, explicit, artists, available_markets, album_uri, popularity) =>\n",
    "        try {\n",
    "          Some(Track(uri, name, duration.toInt, explicit.toBoolean, artists, available_markets, album_uri, popularity.toInt))\n",
    "        } catch {\n",
    "          case _: Throwable => None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "case class Playlist(\n",
    "  uri: String,\n",
    "  name: String,\n",
    "  num_follower: Int,\n",
    ")\n",
    "\n",
    "object Playlist {\n",
    "  def fromCSVLine(line: String): Option[Playlist] = \n",
    "    parseCSVLine(line) match {\n",
    "      case Seq(uri, name, num_follower) =>\n",
    "        try {\n",
    "            Some(Playlist(uri, name, num_follower.toInt))\n",
    "        } catch {\n",
    "          case _: Throwable => None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "case class TrackInPlaylist(\n",
    "  pid: Int,\n",
    "  track_uri: String,\n",
    "  pos: Int,\n",
    ")\n",
    "\n",
    "object TrackInPlaylist {\n",
    "  def fromCSVLine(line: String): Option[TrackInPlaylist] = \n",
    "    parseCSVLine(line) match {\n",
    "      case Seq(pid, track_uri, pos) =>\n",
    "        try {\n",
    "          Some(TrackInPlaylist(pid.toInt, track_uri, pos.toInt))\n",
    "        } catch {\n",
    "          case _: Throwable => None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "case class Artist(\n",
    "  uri: String,\n",
    "  name: String,\n",
    "  followers: Int,\n",
    "  genres: String,             // List of genres, separated by |\n",
    "  popularity: Int,\n",
    ")\n",
    "\n",
    "object Artist {\n",
    "  def fromCSVLine(line: String): Option[Artist] =\n",
    "    parseCSVLine(line) match {\n",
    "      case Seq(uri, name, followers, genres, popularity) =>\n",
    "        try {\n",
    "          Some(Artist(uri, name, followers.toInt, genres, popularity.toInt))\n",
    "        } catch {\n",
    "          case _: Throwable => None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "case class Album(\n",
    "  uri: String,\n",
    "  name: String,\n",
    "  album_type: String,         // album, compilation, single.\n",
    "  artists: String,            // List of artists uri, separated by |\n",
    "  available_markets: String,  // List of markets, separated by |\n",
    "  release_year: String,\n",
    "  total_tracks: Int,\n",
    ")\n",
    "\n",
    "object Album {\n",
    "  def fromCSVLine(line: String): Option[Album] = \n",
    "    parseCSVLine(line) match {\n",
    "      case Seq(uri, name, album_type, artists, available_markets, release_year, total_tracks) =>\n",
    "        try {\n",
    "          Some(Album(uri, name, album_type, artists, available_markets, release_year, total_tracks.toInt))\n",
    "        } catch {\n",
    "          case _: Throwable => None\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "case class Feature(\n",
    "  uri: String,\n",
    "  key: Int,\n",
    "  loudness: String,\n",
    "  tempo: String,\n",
    "  mode: Boolean,\n",
    "  danceability: String,\n",
    "  valence: String,\n",
    "  instrumentalness: String,\n",
    "  liveness: String,\n",
    "  acousticness: String,\n",
    "  energy: String,\n",
    "  speechiness: String,\n",
    ")\n",
    "\n",
    "object Feature {\n",
    "  def fromCSVLine(line: String): Option[Feature] = \n",
    "    parseCSVLine(line) match {\n",
    "      case Seq(uri, key, loudness, tempo, mode, danceability, valence, instrumentalness, liveness, acousticness, energy, speechiness) =>\n",
    "        try {\n",
    "          Some(Feature(uri, key.toInt, loudness, tempo, mode.toInt == 1, danceability, valence, instrumentalness, liveness, acousticness, energy, speechiness))\n",
    "        } catch {\n",
    "          case e: Throwable => None\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val datasetPath = \"dataset/\"\n",
    "\n",
    "val albumRdd = sc.textFile(s\"${datasetPath}albums.csv\").flatMap(Album.fromCSVLine)\n",
    "val artistRdd = sc.textFile(s\"${datasetPath}artists.csv\").flatMap(Artist.fromCSVLine)\n",
    "val featureRdd = sc.textFile(s\"${datasetPath}features.csv\").flatMap(Feature.fromCSVLine)\n",
    "val playlistRdd = sc.textFile(s\"${datasetPath}playlists.csv\").flatMap(Playlist.fromCSVLine)\n",
    "val trackInPlaylistRdd = sc.textFile(s\"${datasetPath}tracks_in_playlists.csv\").flatMap(TrackInPlaylist.fromCSVLine)\n",
    "val trackRdd = sc.textFile(s\"${datasetPath}tracks.csv\").flatMap(Track.fromCSVLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*val albumRddCached = albumRdd.cache()\n",
    "val artistRddCached = artistRdd.cache()\n",
    "val featureRddCached = featureRdd.cache()\n",
    "val playlistRddCached = playlistRdd.cache()\n",
    "val trackInPlaylistRddCached = trackInPlaylistRdd.cache()\n",
    "val trackRddCached = trackRdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(s\"Number of Albums: ${albumRddCached.count()}\")\n",
    "println(s\"Number of Artists: ${artistRddCached.count()}\")\n",
    "println(s\"Number of Track's Feature: ${featureRddCached.count()}\")\n",
    "println(s\"Number of Playlist: ${playlistRddCached.count()}\")\n",
    "println(s\"Number of Tracks add in Playlists: ${trackInPlaylistRddCached.count()}\")\n",
    "println(s\"Number of Tracks: ${trackRddCached.count()}\")*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "- Date le seguenti metriche:\n",
    "  - popolarità della traccia\n",
    "  - popolarità media delle tracce in anno\n",
    "  - popolarità dell'artista (se più artisti, media di essi)\n",
    "Capire come una playlist viene influenzata maggiormente dalle precedenti metriche, mediando i valori delle tracce di cui è composta. Inoltre, aggregare le playlist sull'influenza precedentemente calcolata, mediando per il numero di followers delle playlist.\n",
    "La query permette di rispondere alla seguente domanda:\n",
    "una playlist influenzata maggiormente dalla popolarità delle tracce ha in media 500 followers. (stessa cosa per le altre due metriche di partenza)\n",
    " \n",
    "- Given the following classes: slowly danceable (tempo <= 130BPM, danceability > 0.5), swiftly danceable (tempo >130BPM, danceability > 0.5), slowly undanceable (tempo <= 130BPM, danceability <= 0.5), swiftly undanceable (tempo >130BPM, danceability <= 0.5); and the various keys (C, C#/Db, ...).\n",
    "  for each class and (key ---OR--- range of followers) get:\n",
    "    - The number of playlist.\n",
    "    - Average playlist's percentage.\n",
    "    - Percentage of explicit songs.\n",
    "    - Average number of playlist followers.\n",
    "    - Average tracks tempo\n",
    "    - Average tracks danceability\n",
    "  (The key of a playlist is the most present key among its tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trackWithAlbumUriAsKey = trackRdd.map(t => (t.album_uri, (t.uri, t.popularity)))\n",
    "\n",
    "val avgPopPerYear = albumRdd.map(a => (a.uri, a.release_year)).\n",
    "        join(trackWithAlbumUriAsKey).\n",
    "        map { case (albumUri, (releaseYear, (trackUri, popularity))) => (releaseYear, popularity) }.\n",
    "        aggregateByKey((0, 0))(\n",
    "          { case ((acc, count), popularity) => (acc + popularity, count + 1) },\n",
    "          { case ((acc1, count1), (acc2, count2)) => (acc1 + acc2, count1 + count2) }\n",
    "        ).mapValues { case (acc, count) => acc.toDouble / count } // year -> avg popularity of tracks in that year\n",
    "\n",
    "val trackWithPopularityAndAvgPopInYear = albumRdd.map(a => (a.uri, a.release_year)).\n",
    "        join(trackWithAlbumUriAsKey).\n",
    "        map { case (albumUri, (releaseYear, (trackUri, popularity))) => (releaseYear, (trackUri, popularity)) }.\n",
    "        join(avgPopPerYear).\n",
    "        map { case (releaseYear, ((trackUri, popularity), avgPopularityInYear)) => (trackUri, (popularity, avgPopularityInYear)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val artistWithPopularity = artistRdd.map(a => (a.uri, a.popularity))\n",
    "\n",
    "val trackWithArtistPopularity = trackRdd.flatMap(t => t.artists.split('|').map(artistUri => (artistUri, t.uri))).\n",
    "        join(artistWithPopularity).\n",
    "        map { case (artistUri, (trackUri, artistPopularity)) => (trackUri, artistPopularity) }.\n",
    "        aggregateByKey((0, 0))(\n",
    "          { case ((acc, count), popularity) => (acc + popularity, count + 1) },\n",
    "          { case ((acc1, count1), (acc2, count2)) => (acc1 + acc2, count1 + count2) }\n",
    "        ).mapValues { case (acc, count) => acc.toDouble / count } // track -> avg popularity of artists of that track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trackWithPid = trackInPlaylistRdd.map(t => (t.track_uri, t.pid))\n",
    "\n",
    "val popAvgArtistPop = trackWithPopularityAndAvgPopInYear.join(trackWithArtistPopularity).\n",
    "        map { case (trackUri, ((popularity, avgPopularityInYear), avgArtistPopularity)) => (trackUri, (popularity, avgPopularityInYear, avgArtistPopularity)) }\n",
    "\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "trackWithPid.partitionBy(new HashPartitioner(1)).\n",
    "        join(popAvgArtistPop).\n",
    "        map {\n",
    "            case (trackUri, (pid, (popularity, avgPopularityInYear, avgArtistPopularity))) => (pid, (popularity, avgPopularityInYear, avgArtistPopularity))\n",
    "        }.\n",
    "        aggregateByKey((0.0, 0.0, 0.0, 0))(\n",
    "          { case ((accPop, accAvgPopInYear, accAvgArtistPop, count), (popularity, avgPopularityInYear, avgArtistPopularity)) =>  \n",
    "              (accPop + popularity, accAvgPopInYear + avgPopularityInYear, accAvgArtistPop + avgArtistPopularity, count + 1)\n",
    "          },\n",
    "          { case ((accPop1, accAvgPopInYear1, accAvgArtistPop1, count1), (accPop2, accAvgPopInYear2, accAvgArtistPop2, count2)) =>\n",
    "            (accPop1 + accPop2, accAvgPopInYear1 + accAvgPopInYear2, accAvgArtistPop1 + accAvgArtistPop2, count1 + count2)\n",
    "          }\n",
    "        ).\n",
    "        mapValues { case (accPop, accAvgPopInYear, accAvgArtistPop, count) => (accPop / count, accAvgPopInYear / count, accAvgArtistPop / count) }.\n",
    "        map {\n",
    "            case (pid, (avgPop, avgPopInYear, avgArtistPop)) =>\n",
    "              val maxAvg = Math.max(avgPop, Math.max(avgPopInYear, avgArtistPop))\n",
    "              val indexOfBestAvg = Seq(avgPop, avgPopInYear, avgArtistPop).indexWhere(_ >= maxAvg)\n",
    "              (pid, indexOfBestAvg)\n",
    "        }.take(5).foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
